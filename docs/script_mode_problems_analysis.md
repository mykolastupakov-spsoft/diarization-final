# Промпт для пошуку рішення проблеми Script режиму виділення текстів

## Задача

**Знайди інформацію щодо вирішення моєї проблеми. Ось опис проблеми:**

Я маю систему для аналізу аудіо діаризації, яка використовує script режим (`TEXT_ANALYSIS_MODE=script`) для автоматичного визначення, які фрагменти тексту мають бути виділені синім (Blue), зеленим (Green) або червоним (Red) кольором. Незважаючи на численні спроби покращення алгоритмів, режим не працює коректно - фрази неправильно класифікуються, пропускаються, або потрапляють в кілька категорій одночасно.

## Опис проблеми

### Що має працювати

Система отримує дані з трьох джерел:
1. **`general`** - первинна діаризація всього аудіо з обома спікерами (Step 1)
2. **`speaker1` та `speaker2`** - окремі треки для кожного спікера після розділення аудіо (Step 3)
3. **`markdown`** - виправлена таблиця, згенерована LLM (Step 5)

Система має класифікувати фрази з markdown таблиці на три категорії:

- **Blue (Синій)**: Фрази, які є і в `general`, і в `speaker1` або `speaker2` треках. Це звичайна діаризація - стандартні, неперекриваючі сегменти.
- **Green (Зелений)**: Фрази, які є в `speaker1`/`speaker2` треках, але відсутні в `general`. Це overlap recognition - фрази, виявлені на третьому етапі, але пропущені в початковій діаризації.
- **Red (Червоний)**: Фрази, які є в markdown таблиці, але відсутні у всіх трьох джерелах (`general`, `speaker1`, `speaker2`). Це hallucinations - фрази, додані LLM, яких немає в жодному записі.

### Поточні проблеми

1. **Неправильне визначення кольорів**: Фрази, які мають бути зеленими (є в tracks, немає в general), виділяються червоним кольором.

2. **Пропуск фраз**: Деякі фрази взагалі не виділяються, навіть якщо вони мають бути виділені.

3. **Дублювання між категоріями**: Одна і та ж фраза може потрапити в кілька категорій одночасно (Blue, Green, Red).

4. **Проблеми з часом (timestamps)**: Фрази з однаковим текстом, але з різними timestamps, не співставляються правильно.

5. **КРИТИЧНА ПРОБЛЕМА: Змішані репліки з різними частинами**:
   - **Симптом**: Одна репліка (сегмент) може містити різні частини, які мають різні кольори:
     - Частина тексту присутня в аудіо треках (speaker1/speaker2) → має бути **Green**
     - Частина тексту присутня в першому JSON (general) → має бути **Blue**
     - Частина тексту є галюцинаціями (відсутня в усіх джерелах) → має бути **Red**
   - **Поточна поведінка**: Вся репліка класифікується як один колір (зазвичай Red), навіть якщо вона містить частини, які мають бути різних кольорів
   - **Приклад**: Репліка "Hello, I understand, thank you very much" може містити:
     - "Hello" - є в general → Blue
     - "I understand" - є в tracks, але не в general → Green
     - "thank you very much" - відсутня в усіх джерелах → Red
   - **Проблема**: Система класифікує всю репліку як Red, оскільки вона не знаходить повного збігу в жодному джерелі
   - **Вимога**: Потрібна **word-level або sub-phrase level класифікація**, де кожне слово або фраза класифікується окремо на основі її наявності в різних джерелах

## Структура даних

### Вхідні дані (Payload)

Функція `analyzeText(payload)` отримує об'єкт з наступною структурою:

```javascript
{
  general: {
    segments: [...],              // Або
    speechmatics: {
      segments: [...]
    }
  },
  speaker1: {
    segments: [...],              // Або
    speechmatics: {
      segments: [...]
    },
    speaker: "SPEAKER_00",        // Опціонально
    role: "agent"                 // Опціонально
  },
  speaker2: {
    segments: [...],              // Або
    speechmatics: {
      segments: [...]
    },
    speaker: "SPEAKER_01",        // Опціонально
    role: "client"                // Опціонально
  },
  markdown: "| Segment ID | ..."  // Markdown таблиця (опціонально)
}
```

### Структура сегмента

Кожен сегмент має структуру:

```javascript
{
  text: "Hello, how can I help you?",  // Текст сегмента (string)
  start: 0.64,                          // Початок в секундах (number)
  end: 2.15,                            // Кінець в секундах (number)
  speaker: "SPEAKER_00"                 // Ідентифікатор спікера (string)
}
```

### Вихідні дані

Функція повертає об'єкт з трьома масивами:

```javascript
{
  Blue: [
    { text: "string", start: number, end: number, speaker: "string" },
    ...
  ],
  Green: [
    { text: "string", start: number, end: number, speaker: "string" },
    ...
  ],
  Red: [
    { text: "string", start: number, end: number, speaker: "string" },
    ...
  ]
}
```

## Джерела даних

### 1. `general` (Primary Diarization - Step 1)

**Джерело**: Первинна діаризація всього аудіо файлу з обома спікерами одночасно через Speechmatics API.

**Особливості**:
- Містить обидва голоси одночасно
- Може пропускати фрази, які говоряться одночасно (overlap)
- Timestamps можуть відрізнятися від voice tracks через різну сегментацію
- Формат спікера: `SPEAKER_00`, `SPEAKER_01` (Speechmatics формат)

**Де знаходиться в коді**: `server.js` (рядки 3676-3688), `lib/textAnalysis.js` (рядки 762-764)

### 2. `speaker1` та `speaker2` (Voice Tracks - Step 3)

**Джерело**: Окремі треки для кожного спікера, створені після розділення аудіо (AudioShake, PyAnnote, або SpeechBrain), потім транскрибовані через Speechmatics API.

**Особливості**:
- Містить тільки один голос (ізольований трек)
- Може містити фрази, які були пропущені в `general` через overlap
- Timestamps можуть відрізнятися від `general` через різну сегментацію
- Може містити додаткові метадані: `role`, `roleConfidence`, `roleSummary`

**Де знаходиться в коді**: `server.js` (рядки 3689-3720), `lib/textAnalysis.js` (рядки 753-759)

### 3. `markdown` (LLM-Corrected Table - Step 5)

**Джерело**: Markdown таблиця, згенерована LLM для виправлення та дедуплікації сегментів.

**Формат markdown таблиці**:
```markdown
| Segment ID | Speaker | Text | Start Time | End Time |
|------------|---------|------|------------|----------|
| 1 | Agent | Hello, how can I help you? | 0.64 | 2.15 |
| 2 | Client | Yes, I need assistance | 1.5 | 2.8 |
```

**Особливості**:
- Може містити фрази, яких немає в жодному джерелі (hallucinations → Red)
- Може містити перекриваючі сегменти (End попереднього > Start наступного)
- Формат спікера: `Agent`, `Client` (LLM формат, не Speechmatics)
- Timestamps можуть відрізнятися від джерел через LLM корекцію

**Де знаходиться в коді**: `server.js` (рядки 4037-4200), `lib/textAnalysis.js` (рядки 577-650, 501-560)

### Потік даних

```
Аудіо файл
    ↓
[Step 1] Speechmatics Primary Diarization
    ↓
general.segments (обидва спікери)
    ↓
[Step 2] Audio Separation (AudioShake/PyAnnote/SpeechBrain)
    ↓
[Step 3] Speechmatics Voice Track 1 Transcription
    ↓
speaker1.segments (тільки спікер 1)
    ↓
[Step 3] Speechmatics Voice Track 2 Transcription
    ↓
speaker2.segments (тільки спікер 2)
    ↓
[Step 4] Role Analysis (LLM)
    ↓
speaker1.role, speaker2.role
    ↓
[Step 5] LLM Markdown Generation
    ↓
markdown (виправлена таблиця)
    ↓
[Step 6] Text Analysis (Script або LLM)
    ↓
{ Blue: [...], Green: [...], Red: [...] }
```

### Формати даних

**Формат спікерів**:
- Speechmatics: `SPEAKER_00`, `SPEAKER_01` (в `general`, `speaker1`, `speaker2`)
- LLM Markdown: `Agent`, `Client` (в `markdown` таблиці)
- Role Analysis: `agent`, `client`, `operator`, `customer` (в `speaker1.role`, `speaker2.role`)

**Формат timestamps**: `number` (секунди, десяткові дроби), наприклад: `0.64`, `2.15`, `1.5`

**Формат тексту**: `string` (UTF-8), може містити пунктуацію, пробіли, спеціальні символи

## Підходи, які вже пробував

### 1. Покращення функції `computeTextSimilarity`
- Додав перевірку на substring matching
- Додав Jaccard similarity
- Додав word sequence matching
- Комбінував різні метрики
- **Результат**: Деяке покращення, але все ще були пропуски. Проблема з короткими фразами залишилася.

### 2. Покращення функції `existsInPrimary`
- Додав перевірку time overlap
- Додав time distance calculation
- Повертав детальний об'єкт `{ found, similarity, timeMatch }`
- **Результат**: Покращило визначення наявності, але не вирішило всі проблеми. Все ще були випадки неправильної класифікації.

### 3. Налаштування порогів
- Змінював `similarityThreshold` (0.7, 0.8, 0.9)
- Змінював `timeTolerance` (0.1, 0.5, 1.0 секунди)
- Робив різні пороги для коротких і довгих фраз
- **Результат**: Зниження порогів призводило до false positives. Підвищення порогів призводило до пропусків. Не вдалося знайти оптимальний баланс.

### 4. Додавання дедуплікації
- Додав пріоритетність: Blue > Green > Red
- Перевіряв, чи фраза вже є в іншій категорії перед додаванням
- **Результат**: Вирішило проблему дублювання. Але не вирішило проблему неправильної класифікації.

### 5. Покращення обробки коротких фраз
- Знижував мінімальну довжину фрази
- Додавав спеціальну обробку для коротких фраз (< 3 символів)
- Змінював пороги схожості для коротких фраз
- **Результат**: Деяке покращення, але все ще були пропуски. Проблема з дуже короткими словами залишилася.

### 6. Додавання перевірки на overlapping segments
- Додав функцію `findOverlappingSegments()` для виявлення перекривань у markdown таблиці
- Додав спеціальну логіку для обробки overlapping segments
- **Результат**: Покращило визначення Green для overlapping segments. Але не вирішило проблему для non-overlapping segments.

### 7. Покращення word-level highlighting
- Змінив з phrase-level на word-level highlighting
- Додав функцію `findWordsInText()` для пошуку окремих слів
- Додав багатоступеневий пошук (exact, normalized, word-by-word)
- **Результат**: Покращило точність виділення на рівні слів. Але не вирішило проблему з класифікацією кольорів.

## Що не працювало та чому

### 1. Текстова схожість
**Проблема**: Різні варіанти написання одного і того ж тексту (з пунктуацією, без пунктуації, з різними пробілами) не співставлялися правильно.

**Спроби**: Нормалізація тексту, різні метрики схожості.

**Чому не працювало**: 
- Нормалізація не завжди достатня (наприклад, "don't" vs "do not")
- Різні метрики дають різні результати, важко знайти оптимальну комбінацію

### 2. Визначення наявності в джерелах
**Проблема**: Функція `existsInPrimary()` не завжди правильно визначала, чи є фраза в джерелі.

**Спроби**: Додавання time overlap, time distance, комбінування метрик.

**Чому не працювало**:
- Складність визначення, чи одна і та ж фраза з різними timestamps - це одна фраза чи різні
- Різні джерела можуть мати трохи різні timestamps для однієї фрази

### 3. Класифікація Green vs Red
**Проблема**: Фрази, які мають бути Green (є в tracks, немає в general), класифікувалися як Red.

**Спроби**: 
- Перевірка наявності в tracks перед перевіркою в general
- Фільтрація Green з Red
- Покращення логіки перевірки

**Чому не працювало**:
- Складність визначення, чи фраза "є" в джерелі, якщо текст схожий, але не ідентичний
- Різні джерела можуть мати трохи різні формулювання однієї фрази

### 4. Обробка коротких фраз
**Проблема**: Короткі фрази (1-2 слова) часто пропускалися або неправильно класифікувалися.

**Спроби**: Спеціальна обробка для коротких фраз, зниження порогів.

**Чому не працювало**:
- Короткі фрази мають високу ймовірність збігу випадково
- Важко визначити, чи це справді одна фраза, чи просто збіг

### 5. Speaker filtering
**Проблема**: Фрази іншого спікера потрапляли в Blue/Green замість Red.

**Спроби**: Додавання перевірки speaker перед додаванням до Blue/Green.

**Чому не працювало**:
- Різні джерела можуть мати різні формати спікерів (SPEAKER_00 vs Agent vs Client)
- Складність визначення, чи спікер відповідає, якщо формати різні

## Технічні деталі реалізації

### Функції, які використовуються

1. **`normalizeText(text)`** - Нормалізує текст для порівняння
   - Перетворює в lowercase
   - Видаляє пунктуацію
   - Нормалізує пробіли
   - **Проблема**: Може видалити важливу інформацію (наприклад, "don't" vs "do not")

2. **`computeTextSimilarity(text1, text2)`** - Обчислює схожість двох текстів
   - Використовує substring matching
   - Використовує Jaccard similarity
   - Використовує word sequence matching
   - **Проблема**: Не враховує семантику

3. **`existsInPrimary(segment, primarySegments, threshold, timeTolerance)`** - Перевіряє наявність сегмента
   - Повертає `{ found: boolean, similarity: number, timeMatch: boolean }`
   - Враховує time overlap та time distance
   - **Проблема**: Не завжди правильно визначає наявність

4. **`findRepeatedPhrases(payload)`** - Знаходить Blue фрази
   - Шукає фрази, які є і в `general`, і в `speaker1`/`speaker2`
   - **Проблема**: Може пропустити фрази через строгі пороги

5. **`findOverlaps(payload)`** - Знаходить Green фрази
   - Шукає фрази, які є в `speaker1`/`speaker2`, але немає в `general`
   - **Проблема**: Може класифікувати як Red через неправильну перевірку

6. **`findDiscrepancies(payload)`** - Знаходить Red фрази
   - Шукає фрази з `markdown`, яких немає в жодному джерелі
   - **Проблема**: Може класифікувати Green фрази як Red

7. **`findOverlappingSegments(markdown)`** - Знаходить перекриваючі сегменти
   - Парсить markdown таблицю
   - Знаходить сегменти, де End попереднього > Start наступного
   - **Проблема**: Може не знайти всі перекриття через помилки парсингу

### Поточні пороги та параметри

- **Blue similarity threshold**: 0.65 (або 0.5 для коротких фраз)
- **Green similarity threshold**: 0.55 (або 0.4 для коротких фраз)
- **Red similarity threshold**: 0.55 (або 0.45 для коротких фраз)
- **Blue time tolerance**: 2.5 секунди
- **Green time tolerance**: 4.0 секунди
- **Red time tolerance**: 2.5 секунди
- **Мінімальна довжина фрази**: 1 символ (було 3)

**Проблеми з порогами**:
- Різниця між порогами невелика (0.05-0.1), що може призвести до невизначеності
- Пороги не враховують тип фрази (коротка, довга, з пунктуацією)
- Пороги не враховують контекст (overlap, non-overlap)

### Алгоритм виконання

1. Валідація payload - Перевірка наявності даних
2. Знаходження overlapping segments - Парсинг markdown таблиці
3. Обробка overlapping segments - Класифікація Green/Red для перекривань
4. Знаходження Blue фраз - `findRepeatedPhrases()`
5. Знаходження Green фраз - `findOverlaps()`
6. Знаходження Red фраз - `findDiscrepancies()`
7. Дедуплікація - Виключення дублікатів між категоріями (Blue > Green > Red)
8. Повернення результату - `{ Blue: [], Green: [], Red: [] }`

## Конкретні приклади проблем

### Приклад 1: Неправильна класифікація Green → Red
**Ситуація**: Фраза "Yes, I understand" є в `speaker1` треку, але відсутня в `general`
**Очікуваний результат**: Green
**Фактичний результат**: Red
**Причина**: Функція `existsInVoiceTracks` не знайшла фразу через:
- Різницю в нормалізації тексту
- Різницю в timestamps
- Занадто високий поріг схожості

### Приклад 2: Пропуск коротких фраз
**Ситуація**: Фраза "OK" є в `general` і в `speaker1`
**Очікуваний результат**: Blue
**Фактичний результат**: Не виділяється
**Причина**: 
- Коротка фраза (2 символи) має низьку схожість через випадкові збіги
- Word boundary не працює для таких коротких слів
- Поріг схожості занадто високий для коротких фраз

### Приклад 3: Дублювання між категоріями
**Ситуація**: Фраза "Thank you" є в `general`, `speaker1`, і в markdown таблиці
**Очікуваний результат**: Blue (тільки)
**Фактичний результат**: Blue, Green, Red (всі три)
**Причина**: 
- Різні пороги схожості для різних категорій
- Відсутність дедуплікації на етапі обчислення
- Різні timestamps в різних джерелах

### Приклад 4: КРИТИЧНА ПРОБЛЕМА - Змішані репліки
**Ситуація**: Репліка "Hello, I understand, thank you very much" з markdown таблиці:
- "Hello" → є в `general` (Blue)
- "I understand" → є в `speaker1` tracks, але не в `general` (Green)
- "thank you very much" → відсутня в усіх джерелах (Red)

**Очікуваний результат**: 
- "Hello" → Blue
- "I understand" → Green
- "thank you very much" → Red

**Фактичний результат**: Вся репліка класифікується як Red

**Причина**: 
- Система перевіряє всю репліку як ціле
- Не знаходить повного збігу в жодному джерелі
- Не виконує word-level або phrase-level класифікацію
- Не може визначити, яка частина репліки відповідає якому джерелу
- Відсутність sub-phrase matching в alignment engine

## Пробіли в знаннях

### 1. Недостатнє розуміння структури даних
- Як точно виглядають дані з `general.speechmatics.segments`
- Як точно виглядають дані з `speaker1.speechmatics.segments`
- Як точно виглядають дані з markdown таблиці
- Чи завжди є всі поля (text, start, end, speaker) в усіх джерелах
- Як форматуються спікери в різних джерелах (SPEAKER_00 vs Agent vs Client)
- Чи можуть бути різні формати timestamps (секунди, мілісекунди, рядки)

### 2. Недостатнє розуміння логіки діаризації
- Чому одна і та ж фраза може мати різні timestamps в різних джерелах
- Чому фраза може бути в tracks, але не в general (overlap)
- Як точно визначається overlap в діаризації
- Чому LLM може додавати фрази, яких немає в жодному джерелі (hallucinations)

### 3. Недостатнє розуміння метрик схожості
- Яка метрика найкраще працює для транскрипцій (Jaccard, Levenshtein, word sequence, substring)
- Які пороги оптимальні для різних типів фраз (короткі, довгі, з пунктуацією)
- Як комбінувати різні метрики для найкращого результату

### 4. Недостатнє розуміння обробки часу
- Який tolerance для часу оптимальний (0.1s, 0.5s, 1.0s)
- Як обробляти випадки, коли фраза має різні timestamps в різних джерелах
- Чи потрібно враховувати time overlap при визначенні схожості

### 5. Недостатнє розуміння нормалізації тексту
- Чи потрібно видаляти всю пунктуацію чи тільки частину
- Як обробляти скорочення ("don't" vs "do not")
- Як обробляти різні варіанти написання одного слова
- Чи потрібно враховувати регістр

### 6. Недостатнє розуміння пріоритетності
- Чи правильна пріоритетність Blue > Green > Red
- Як обробляти випадки, коли фраза частково відповідає кільком категоріям
- Чи потрібно враховувати confidence score при визначенні категорії

### 7. Недостатнє розуміння тестування
- Які саме дані приходять в реальних випадках
- Які саме проблеми виникають з реальними даними
- Як виглядають edge cases в реальних даних
- Які саме фрази мають бути Blue/Green/Red в конкретних прикладах
- Які саме фрази пропускаються і чому

### 8. Недостатнє розуміння семантики тексту
- Як визначити, чи "I'm" і "I am" - це одна фраза чи різні
- Як визначити, чи "don't" і "do not" - це одна фраза чи різні
- Як обробляти синоніми та варіанти формулювань
- Як враховувати контекст при визначенні схожості

### 9. Недостатнє розуміння обробки помилок транскрибації
- Як часто виникають помилки транскрибації
- Які типи помилок найбільш поширені (заміна букв, пропуск слів, додавання слів)
- Як помилки впливають на визначення схожості
- Чи потрібно враховувати помилки при визначенні наявності в джерелах

### 10. Недостатнє розуміння обробки перекриттів (overlaps)
- Як точно визначається overlap в діаризації
- Чи завжди overlap означає, що фраза має бути Green
- Як обробляти випадки, коли overlap є, але фраза також є в general
- Як визначати, яка частина фрази належить якому спікеру при overlap

### 11. Недостатнє розуміння word-level та sub-phrase класифікації
- Як розбивати репліки на слова/фрази для окремої класифікації
- Як визначати, яка частина репліки відповідає якому джерелу
- Як обробляти змішані репліки з різними частинами
- Як виконувати sub-phrase matching для знаходження часткових збігів
- Як використовувати natural language boundaries (коми, точки) для сегментації
- Як враховувати часовий контекст для окремих слів/фраз всередині репліки

## Text Alignment алгоритми та підходи

### Існуючі реалізації в коді

#### 1. `alignSpeakerSegmentsForTable` (app.js, рядки 7381-7512)
**Призначення**: Вирівнювання сегментів двох спікерів хронологічно для side-by-side порівняння.

**Алгоритм**:
- Сортування сегментів за `start` time
- Об'єднання послідовних сегментів одного спікера (якщо проміжок < `maxSameSpeakerGap`, за замовчуванням 3.0 секунди)
- Створення рядків з парами сегментів (speaker1Segment, speaker2Segment)
- Враховує хронологічний порядок та перекриття

**Параметри**:
- `maxSameSpeakerGapSeconds`: Максимальний проміжок між сегментами одного спікера для об'єднання (за замовчуванням 3.0 секунди)

**Обмеження**: Не використовує text similarity для вирівнювання, тільки timestamps.

#### 2. Hungarian Algorithm для вирівнювання спікерів (metrics.js, рядки 59-123)
**Призначення**: Вирівнювання міток спікерів між reference та hypothesis діаризаціями.

**Алгоритм**:
- Створення confusion matrix на основі time overlap
- Обчислення overlap для кожної пари спікерів з роздільною здатністю 10ms
- Greedy assignment: для кожного reference спікера знаходить найкраще відповідність з hypothesis

**Параметри**:
- `resolution`: 0.01 секунди (10ms) для обчислення overlap

**Обмеження**: Використовує тільки time overlap, не враховує text similarity.

#### 3. Text Similarity Utils (text_similarity_utils.js)
**Призначення**: Порівняння текстів з використанням множинних метрик.

**Метрики**:
1. **Levenshtein Distance**: Для виявлення typo та варіацій
2. **Jaccard Similarity**: На tokenized тексті (intersection / union)
3. **Substring Matching**: Перевірка, чи один текст містить інший
4. **Combined Score**: Комбінація Levenshtein (60%) + Jaccard (40%)

**Пороги** (за замовчуванням):
- `minLevenshteinSim`: 0.88
- `minJaccardSim`: 0.80
- `minSubstringMatch`: 0.75
- `combinedScore`: 0.82

**Обмеження**: Не враховує timestamps, тільки текст.

### Рекомендовані підходи для text alignment

#### 1. Sequence Alignment алгоритми
**Smith-Waterman Algorithm**: Для локального вирівнювання послідовностей
- Підходить для знаходження схожих підпослідовностей у різних транскрипціях
- Враховує gaps (пропуски) та mismatches (невідповідності)
- Може бути адаптований для роботи з timestamps

**Needleman-Wunsch Algorithm**: Для глобального вирівнювання
- Підходить для вирівнювання повних транскрипцій
- Може використовуватися для знаходження відповідностей між сегментами

#### 2. Dynamic Time Warping (DTW)
**Призначення**: Вирівнювання послідовностей з різними timestamps
- Підходить для випадків, коли одна фраза має різні timestamps в різних джерелах
- Враховує як текст, так і час
- Може бути комбінований з text similarity

#### 3. Multi-dimensional Alignment
**Підхід**: Комбінування кількох вимірів для вирівнювання
- **Text similarity**: Levenshtein, Jaccard, substring matching
- **Time overlap**: Перевірка перекриття timestamps
- **Time distance**: Відстань між timestamps
- **Speaker matching**: Відповідність спікерів

**Scoring function**: 
```
score = w1 * textSimilarity + w2 * timeOverlap + w3 * (1 / timeDistance) + w4 * speakerMatch
```

#### 4. Graph-based Alignment
**Підхід**: Побудова графа відповідностей між сегментами
- Вузли: сегменти з різних джерел
- Ребра: потенційні відповідності з вагами (score)
- Алгоритм: знаходження оптимального matching (наприклад, Hungarian algorithm)

#### 5. Hierarchical Alignment
**Підхід**: Багаторівневе вирівнювання
1. **Рівень 1**: Грубе вирівнювання на основі timestamps (time windows)
2. **Рівень 2**: Точне вирівнювання на основі text similarity в межах time windows
3. **Рівень 3**: Фінальна перевірка на основі комбінованих метрик

## КРИТИЧНА ПРОБЛЕМА: Змішані репліки з різними частинами

### Опис проблеми

**Симптом**: Одна репліка (сегмент з markdown таблиці) може містити різні частини тексту, які мають різні кольори, але система класифікує всю репліку як один колір.

**Приклад проблеми**:
```
Репліка з markdown: "Hello, I understand, thank you very much"
- "Hello" → є в general → має бути Blue
- "I understand" → є в tracks, але не в general → має бути Green  
- "thank you very much" → відсутня в усіх джерелах → має бути Red
```

**Поточна поведінка**: Система перевіряє всю репліку як ціле і, не знайшовши повного збігу, класифікує її як Red.

**Потрібна поведінка**: Кожне слово або фраза в репліці має класифікуватися окремо на основі її наявності в різних джерелах.

### Гепи в поточному підході

1. **Сегмент-рівнева класифікація замість word-level**:
   - Поточна система працює на рівні цілих сегментів/фраз
   - Не враховує, що один сегмент може містити частини з різними джерелами
   - Не може розділити сегмент на підчастини для окремої класифікації

2. **Відсутність sub-phrase matching**:
   - Система шукає повний збіг сегмента в джерелах
   - Не перевіряє, чи окремі слова/фрази з сегмента присутні в різних джерелах
   - Не може визначити, яка частина сегмента відповідає якому джерелу

3. **Бінарна класифікація (found/not found)**:
   - Система використовує бінарну логіку: сегмент або знайдено, або ні
   - Не враховує часткові збіги або змішані джерела
   - Не може визначити, яка частина сегмента знайдена в якому джерелі

4. **Відсутність word-level alignment**:
   - Alignment engine працює на рівні цілих сегментів
   - Не виконує word-by-word або phrase-by-phrase alignment
   - Не може визначити, які слова з сегмента відповідають яким словам у джерелах

5. **Відсутність сегментації реплік**:
   - Система не розбиває довгі репліки на менші частини для окремої перевірки
   - Не використовує natural language boundaries (коми, точки, паузи) для сегментації
   - Не враховує часові межі окремих слів/фраз всередині репліки

### Потрібні виправлення

1. **Word-level або phrase-level класифікація**:
   - Розбити кожну репліку на слова або фрази
   - Класифікувати кожне слово/фразу окремо на основі її наявності в джерелах
   - Об'єднати результати для формування змішаного виділення

2. **Sub-phrase matching в alignment engine**:
   - Розширити alignment engine для підтримки sub-phrase matching
   - Додати можливість знаходити часткові збіги всередині сегментів
   - Враховувати позиції слів/фраз всередині сегментів

3. **Multi-source classification**:
   - Перевіряти кожне слово/фразу на наявність у всіх джерелах одночасно
   - Визначати, в яких джерелах присутня кожна частина
   - Класифікувати на основі комбінації джерел (Blue = general + tracks, Green = tracks only, Red = none)

4. **Часовий контекст для підчастин**:
   - Використовувати timestamps для окремих слів/фраз (якщо доступні)
   - Враховувати часовий контекст при перевірці наявності підчастин
   - Використовувати time windows для грубого фільтрування перед детальною перевіркою

5. **Natural language segmentation**:
   - Розбивати репліки на фрази за допомогою punctuation (коми, точки)
   - Використовувати паузи або часові розриви для сегментації
   - Враховувати синтаксичні межі (clause boundaries) для кращої сегментації

### Додаткові гепи в поточному підході

6. **Відсутність контекстного аналізу**:
   - Система не враховує контекст навколо слова/фрази при класифікації
   - Не використовує сусідні слова для покращення точності
   - Не враховує послідовність слів при визначенні наявності

7. **Відсутність обробки складених фраз**:
   - Система не може обробляти фрази, які складаються з кількох частин
   - Не враховує, що одна фраза може бути розбита на частини в різних джерелах
   - Не може об'єднати частини фрази з різних джерел для формування повної картини

8. **Відсутність обробки перекриттів всередині реплік**:
   - Система не враховує, що різні частини репліки можуть мати різні timestamps
   - Не може визначити, яка частина репліки відповідає якому часовому діапазону
   - Не враховує часові перекриття між частинами репліки та джерелами

9. **Відсутність обробки варіацій формулювань**:
   - Система не враховує, що одна ідея може бути виражена різними словами
   - Не може визначити семантичну еквівалентність між різними формулюваннями
   - Не використовує синоніми або парафрази для знаходження відповідностей

10. **Відсутність обробки помилок транскрибації на word-level**:
    - Система не враховує, що окремі слова можуть бути неправильно транскрибовані
    - Не може визначити, чи слово з помилкою відповідає правильному слову в джерелі
    - Не використовує fuzzy matching на рівні окремих слів

## Що потрібно знайти (з акцентом на word-level класифікацію)

### КРИТИЧНО ВАЖЛИВО: Word-level або Phrase-level класифікація

**Основна проблема**: Поточна система працює на рівні цілих сегментів/реплік і не може обробляти змішані репліки, де різні частини мають різні кольори.

**Потрібні рішення**:
1. **Алгоритми розбиття реплік на слова/фрази**:
   - Natural language segmentation (за punctuation, паузами, синтаксичними межами)
   - Word tokenization з урахуванням контексту
   - Phrase detection (визначення фразових одиниць)

2. **Word-level alignment алгоритми**:
   - Sequence alignment для визначення відповідностей між окремими словами
   - Substring matching для знаходження часткових збігів
   - Fuzzy word matching для обробки помилок транскрибації

3. **Multi-source word classification**:
   - Перевірка кожного слова на наявність у всіх джерелах
   - Визначення, в яких джерелах присутнє кожне слово
   - Класифікація на основі комбінації джерел

4. **Об'єднання результатів**:
   - Формування змішаного виділення з різними кольорами для різних частин
   - Обробка меж між частинами різних кольорів
   - Врахування контексту при об'єднанні

### Інші потрібні рішення

1. **Алгоритми та підходи** для покращення визначення схожості текстів у транскрипціях
   - Sequence alignment алгоритми (Smith-Waterman, Needleman-Wunsch) для sub-phrase matching
   - Dynamic Time Warping (DTW) для вирівнювання з різними timestamps на word-level
   - Graph-based alignment для знаходження оптимальних відповідностей між словами/фразами
   - Word-level alignment алгоритми для визначення відповідностей між окремими словами

2. **Метрики схожості**, які найкраще працюють для транскрипцій з різними варіантами написання
   - Комбіновані метрики (text + time + speaker)
   - Адаптивні пороги залежно від довжини фрази
   - Confidence scores для кожної метрики
   - **КРИТИЧНО**: Word-level або phrase-level метрики для sub-phrase matching

3. **Стратегії обробки timestamps** при порівнянні сегментів з різних джерел
   - Time windows для грубого фільтрування
   - Time overlap calculation для точного вирівнювання
   - Time distance normalization

4. **Підходи до нормалізації тексту** для транскрипцій, які зберігають важливу інформацію
   - Phonetic normalization для скорочень ("don't" → "do not")
   - Context-aware normalization
   - Збереження важливих маркерів (питальні знаки, вигуки)

5. **Методи класифікації** для визначення, чи фраза "є" в джерелі, якщо текст схожий, але не ідентичний
   - Multi-stage matching (грубе → точне)
   - Fuzzy matching з confidence scores
   - Machine learning підходи для класифікації
   - **КРИТИЧНО**: Sub-phrase matching для знаходження часткових збігів всередині реплік
   - **КРИТИЧНО**: Word-by-word або phrase-by-phrase класифікація для змішаних реплік

6. **Стратегії обробки коротких фраз** для уникнення false positives та пропусків
   - Контекстне вирівнювання (враховувати сусідні сегменти)
   - Знижені пороги для коротких фраз з додатковою перевіркою
   - Word-level alignment для коротких фраз

7. **Підходи до обробки overlaps** в діаризації для правильного визначення Green фраз
   - Overlap detection на основі timestamps
   - Multi-speaker alignment для overlapping segments
   - Partial matching для частково перекриваючих сегментів

8. **Методи визначення пріоритетності** при класифікації фраз, які можуть належати до кількох категорій
   - Confidence-based priority (вища confidence → вищий пріоритет)
   - Multi-criteria decision making
   - Machine learning для визначення найкращої категорії

9. **Стратегії обробки різних форматів спікерів** (SPEAKER_00 vs Agent vs Client)
   - Speaker mapping на основі time overlap (як в metrics.js)
   - Role-based mapping (agent → SPEAKER_00, client → SPEAKER_01)
   - Fuzzy speaker matching

10. **Підходи до тестування та валідації** алгоритмів класифікації текстів
    - Ground truth datasets для тестування
    - Metrics для оцінки точності (precision, recall, F1)
    - A/B testing для порівняння різних підходів
    - **КРИТИЧНО**: Тестові випадки зі змішаними репліками для перевірки word-level класифікації

## Контекст коду

**Файли з реалізацією**:
- `lib/textAnalysis.js` - основна логіка аналізу (функції `analyzeText`, `findRepeatedPhrases`, `findOverlaps`, `findDiscrepancies`)
- `server.js` - виклики функцій аналізу (рядки 3749-3770, 4228-4249, 12310-12341)
- `public/demo.html` - клієнтська частина для демо сторінки

**Функція виклику**: `analyzeText(payload)` в `lib/textAnalysis.js` (рядок 744)

**API endpoint**: `POST /api/analyze-text` в `server.js` (рядок 12242)

**Environment variable**: `TEXT_ANALYSIS_MODE=script` для використання script режиму

## Очікуваний результат

Потрібно знайти рішення, яке:
1. Правильно класифікує фрази на Blue, Green, Red
2. **КРИТИЧНО**: Підтримує word-level або phrase-level класифікацію для змішаних реплік
3. **КРИТИЧНО**: Може класифікувати різні частини однієї репліки різними кольорами
4. **КРИТИЧНО**: Може визначити, яка частина репліки відповідає якому джерелу
5. **КРИТИЧНО**: Підтримує sub-phrase matching для знаходження часткових збігів
6. Не пропускає фрази, які мають бути виділені
7. Не допускає дублювання між категоріями
8. Правильно обробляє різні timestamps для однієї фрази
9. Правильно обробляє короткі фрази
10. Правильно обробляє overlaps
11. Правильно обробляє різні формати спікерів
12. Працює з реальними даними з усіма їх особливостями
13. **КРИТИЧНО**: Може обробляти змішані репліки, де різні частини мають різні джерела
14. **КРИТИЧНО**: Використовує natural language segmentation для розбиття реплік на частини
15. **КРИТИЧНО**: Враховує контекст при класифікації окремих слів/фраз
