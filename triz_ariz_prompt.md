# АРИЗ (Алгоритм Рішення Інноваційних Задач) - Аналіз проблеми об'єднання транскриптів

## Інструкція для GPT моделі

Ти - експерт з ТРИЗ (Теорія Рішення Інноваційних Задач). Твоє завдання - провести повний аналіз технічної проблеми за методологією АРИЗ (Алгоритм Рішення Інноваційних Задач) та знайти ідеальне рішення.

**ВАЖЛИВО**: Слідуй структурі АРИЗ покроково, не пропускай жодного етапу. Кожен етап має бути детально проаналізований перед переходом до наступного.

---

## ЕТАП 1: ФОРМУЛЮВАННЯ ПРОБЛЕМИ

### 1.1. Опис технічної системи

**Система**: Автоматизована система об'єднання транскриптів аудіо з різних джерел діаризації

**Компоненти системи**:
1. **Primary Diarization Module** (Speechmatics)
   - Вхід: Повний аудіофайл з усіма спікерами
   - Вихід: JSON транскрипт з сегментами, кожен має: `speaker`, `text`, `start`, `end`, `role`
   - Точність: Висока точність визначення спікерів, середня точність тексту

2. **Source Separation Module** (SpeechBrain)
   - Вхід: Повний аудіофайл
   - Вихід: Окремі аудіофайли для кожного спікера (SPEAKER_00.wav, SPEAKER_01.wav)
   - Точність: Висока якість розділення, але можливі артефакти

3. **Voice Track Transcription Module** (Speechmatics)
   - Вхід: Окремі аудіофайли від SpeechBrain
   - Вихід: JSON транскрипт для кожного треку
   - Точність: Висока точність тексту, але може виявляти неправильних спікерів

4. **Merge Module** (Програмний алгоритм)
   - Вхід: Primary diarization + Voice track transcripts
   - Вихід: Об'єднаний транскрипт з правильними спікерами та повним текстом
   - Проблема: Неправильне призначення спікерів

### 1.2. Опис проблеми

**Основна проблема**: При об'єднанні транскриптів з primary diarization та voice tracks, текст різних спікерів змішується, що призводить до неправильного призначення спікерів у фінальному виводі.

**Конкретні прояви проблеми**:

1. **Неправильне призначення спікерів**:
   - Voice track для SPEAKER_00 містить сегменти з `speaker: "SPEAKER_01"` або `speaker: "SPEAKER_02"`
   - Це призводить до того, що текст від SPEAKER_01 призначається SPEAKER_00

2. **Дуже довгі сегменти**:
   - Voice track сегменти можуть бути 60+ секунд
   - Такі сегменти містять кілька реплік різних спікерів
   - Неправильно об'єднуються з primary сегментами

3. **Змішування тексту**:
   - Фінальний вивід: "Speaker 1: Hi I'm calling on behalf of Yeah Jessica I do available..."
   - Це об'єднує текст від різних спікерів в одну репліку

### 1.3. Структури даних

**Primary Diarization**:
```json
{
  "recordings": [{
    "results": {
      "speechmatics": {
        "segments": [
          {
            "speaker": "SPEAKER_00",
            "text": "Hi I'm Jessica I'm calling on behalf of Future Health...",
            "start": 0.6,
            "end": 8.24,
            "role": "operator"
          },
          {
            "speaker": "SPEAKER_01",
            "text": "Yeah Jessica I do available What do you have for me",
            "start": 9.36,
            "end": 12.8,
            "role": "client"
          }
        ]
      }
    }
  }]
}
```

**Voice Tracks**:
```json
{
  "speakers": [
    {
      "speaker": "SPEAKER_00",  // Оригінальний спікер треку
      "role": "operator",
      "transcript": {
        "recordings": [{
          "results": {
            "speechmatics": {
              "segments": [
                {
                  "speaker": "SPEAKER_00",  // Може бути іншим!
                  "text": "Hi I'm Jessica...",
                  "start": 0.64,
                  "end": 8.24
                },
                {
                  "speaker": "SPEAKER_01",  // ПРОБЛЕМА: Інший спікер!
                  "text": "Yeah For me",
                  "start": 9.48,
                  "end": 12.8
                }
              ]
            }
          }
        }]
      }
    },
    {
      "speaker": "SPEAKER_01",
      "role": "client",
      "transcript": {
        "recordings": [{
          "results": {
            "speechmatics": {
              "segments": [
                {
                  "speaker": "SPEAKER_00",  // ПРОБЛЕМА: Неправильний спікер!
                  "text": "Hi I'm calling on behalf of",
                  "start": 0.68,
                  "end": 2.64
                },
                {
                  "speaker": "SPEAKER_01",
                  "text": "Yeah Jessica I do available What do you have for me Uh April 29th 1981...",
                  "start": 9.32,
                  "end": 73.69  // ПРОБЛЕМА: Дуже довгий сегмент!
                }
              ]
            }
          }
        }]
      }
    }
  ]
}
```

### 1.4. Поточна реалізація

**Алгоритм мапінгу спікерів**:
1. Групує сегменти по спікерах (track-level підхід)
2. Розраховує загальний temporal overlap між voice speaker та primary speaker
3. Формула: `score = totalOverlap × √(matchCount)`
4. Fallback: Використовує `originalTrackSpeaker` якщо overlap не знайдено

**Алгоритм об'єднання**:
1. Для кожного primary сегменту знаходить перетинаючі voice track сегменти
2. Валідація через guards:
   - Спікер має співпадати (після мапінгу)
   - Temporal overlap >= 0.1s
   - Timestamp distance <= 2.0s
   - Text similarity >= 0.3
3. Вибирає найкращий voice track сегмент
4. Об'єднує текст якщо voice track текст довший і містить primary текст

**Проблеми поточної реалізації**:
- Мапінг спікерів не завжди правильний
- Guards не запобігають змішуванню тексту
- Довгі сегменти не розбиваються
- Немає перевірки на артефакти separation

---

## ЕТАП 2: ВИЗНАЧЕННЯ ТЕХНІЧНОГО ПРОТИРІЧЧЯ

### 2.1. Аналіз функцій системи

**Основна функція (корисна)**:
- Об'єднати транскрипти з primary diarization та voice tracks
- Зберегти правильне призначення спікерів
- Додати відсутній текст з voice tracks

**Шкідливі функції**:
- Неправильне призначення спікерів
- Змішування тексту різних спікерів
- Втрата хронологічного порядку

### 2.2. Формулювання технічного протиріччя

**ТП-1 (Технічне Протиріччя 1)**:
- Якщо ми використовуємо `speaker` з voice track сегменту → отримуємо неправильне призначення спікерів (бо Speechmatics може виявити іншого спікера)
- Якщо ми використовуємо `originalTrackSpeaker` → втрачаємо точність (бо не враховуємо реальний overlap)

**ТП-2**:
- Якщо ми об'єднуємо довгі voice track сегменти → отримуємо змішаний текст від різних спікерів
- Якщо ми не об'єднуємо довгі сегменти → втрачаємо важливий текст

**ТП-3**:
- Якщо ми довіряємо primary diarization для спікерів → отримуємо правильних спікерів, але менш точний текст
- Якщо ми довіряємо voice track transcription для тексту → отримуємо точніший текст, але неправильних спікерів

### 2.3. Визначення ідеального кінцевого результату (ІКР)

**ІКР (Ідеальний Кінцевий Результат)**:
Система сама визначає правильних спікерів та об'єднує текст без додаткових ресурсів та без шкідливих ефектів.

**Конкретніше**:
- Voice track сегменти автоматично отримують правильний `speaker` label на основі їх належності до треку
- Текст об'єднується тільки якщо спікери співпадають
- Довгі сегменти автоматично розбиваються або ігноруються
- Система не потребує додаткових API викликів або ручної перевірки

---

## ЕТАП 3: ВИЗНАЧЕННЯ ФІЗИЧНОГО ПРОТИРІЧЧЯ

### 3.1. Аналіз оперативної зони (ОЗ)

**Оперативна зона**: 
- Момент об'єднання primary сегментів з voice track сегментами
- Процес мапінгу спікерів між двома джерелами
- Валідація та фільтрація сегментів перед об'єднанням

**Оперативний час**:
- Під час виконання функції `mergeTranscriptsProgrammatically`
- Під час мапінгу спікерів в `buildTrackLevelSpeakerMapping`

### 3.2. Формулювання фізичного протиріччя

**ФП-1 (Фізичне Протиріччя 1)**:
- Voice track сегмент має мати `speaker` label, який співпадає з primary speaker (для правильного об'єднання)
- Voice track сегмент має мати `speaker` label, який визначив Speechmatics (для точності transcription)

**ФП-2**:
- Voice track сегмент має бути довгим (щоб містити весь текст)
- Voice track сегмент має бути коротким (щоб не містити текст від інших спікерів)

**ФП-3**:
- Система має довіряти primary diarization для спікерів (висока точність)
- Система має довіряти voice track transcription для тексту (висока точність)
- Але вони конфліктують між собою

---

## ЕТАП 4: ВИКОРИСТАННЯ РЕСУРСІВ

### 4.1. Аналіз доступних ресурсів

**Речовинні ресурси**:
- `originalTrackSpeaker` - оригінальний спікер треку (зберігається в `collectVoiceTrackSegments`)
- `role` - роль спікера (operator/client) з role analysis
- `start`, `end` - таймстемпи сегментів
- `text` - текст сегментів
- `overlap` - інформація про перекриття

**Просторові ресурси**:
- Структура даних дозволяє зберігати додаткові метадані
- Можливість додавати проміжні результати для діагностики

**Часові ресурси**:
- Можливість виконати додаткові перевірки перед об'єднанням
- Можливість зберегти проміжні стани для аналізу

**Функціональні ресурси**:
- `computeTextSimilarity()` - функція для обчислення схожості тексту
- `rangesOverlap()` - функція для перевірки перетину таймстемпів
- `markOverlapFlags()` - функція для маркування перекриттів

**Інформаційні ресурси**:
- Знаємо, що voice track був створений для конкретного спікера
- Знаємо роль спікера з role analysis
- Знаємо temporal overlap між сегментами
- Знаємо схожість тексту між сегментами

### 4.2. Визначення невикористаних ресурсів

**Невикористані ресурси**:
1. **`originalTrackSpeaker`** - використовується тільки як fallback, але може бути основним джерелом правди
2. **`role`** - не використовується для мапінгу спікерів, але може допомогти валідувати
3. **Структура voice tracks** - знаємо, що всі сегменти в `speakers[0].transcript` належать `speakers[0].speaker`
4. **Тривалість сегментів** - не використовується для виявлення проблемних сегментів
5. **Кількість спікерів** - знаємо, скільки спікерів в primary, може допомогти валідувати

---

## ЕТАП 5: ЗАСТОСУВАННЯ СТАНДАРТІВ ТРИЗ

### 5.1. Аналіз прийомів ТРИЗ

**Прийом 2: Винесення (виділення)**
- Винести визначення спікера з voice track transcription
- Використовувати тільки `originalTrackSpeaker` для мапінгу

**Прийом 3: Місцева якість**
- Різні частини системи мають різну якість:
  - Primary diarization: висока точність спікерів
  - Voice track transcription: висока точність тексту
- Використовувати кожну частину для того, що вона робить найкраще

**Прийом 5: Об'єднання**
- Об'єднати інформацію з різних джерел:
  - Спікер з primary diarization
  - Текст з voice track transcription
  - Валідація через `originalTrackSpeaker`

**Прийом 13: Навпаки**
- Замість мапити voice track спікерів до primary спікерів
- Мапити primary сегменти до voice track треків на основі `originalTrackSpeaker`

**Прийом 24: Посередник**
- Використати `originalTrackSpeaker` як посередника між voice track та primary
- Всі сегменти з voice track автоматично отримують спікера з `originalTrackSpeaker`

**Прийом 28: Заміна механічної системи**
- Замість складного алгоритму мапінгу на основі overlap
- Використати просте правило: `voiceTrackSegment.speaker = originalTrackSpeaker`

**Прийом 35: Зміна параметрів**
- Змінити пріоритети:
  - Пріоритет 1: `originalTrackSpeaker` (найвища надійність)
  - Пріоритет 2: Overlap-based mapping (якщо `originalTrackSpeaker` недоступний)
  - Пріоритет 3: Role-based validation

### 5.2. Аналіз стандартів ТРИЗ

**Стандарт 1.2.1: Використання невикористаних ресурсів**
- Використати `originalTrackSpeaker` як основний джерело правди
- Використати `role` для додаткової валідації

**Стандарт 1.2.2: Введення додаткових речовин**
- Додати поле `trustedSpeaker` в voice track сегменти
- Додати поле `segmentDuration` для виявлення проблемних сегментів

**Стандарт 1.2.3: Використання простору**
- Використати структуру voice tracks для визначення спікера
- Всі сегменти в `speakers[i].transcript` автоматично належать `speakers[i].speaker`

**Стандарт 1.2.4: Використання часу**
- Виконати перевірку тривалості сегментів перед об'єднанням
- Відфільтрувати сегменти з підозріло довгою тривалістю (>30 секунд)

**Стандарт 1.2.5: Використання фізичних ефектів**
- Використати структуру даних для автоматичного визначення спікера
- Не потребувати додаткових обчислень

---

## ЕТАП 6: РОЗРОБКА РІШЕННЯ

### 6.1. Генерація ідей рішень

**Ідея 1: Використання originalTrackSpeaker як основного джерела**
- Всі сегменти з voice track автоматично отримують `speaker = originalTrackSpeaker`
- Не потрібен складний мапінг на основі overlap
- Переваги: Простота, надійність
- Недоліки: Може не працювати якщо separation було неправильним

**Ідея 2: Комбінований підхід з валідацією**
- Використовувати `originalTrackSpeaker` як основний
- Валідувати через overlap та role
- Відфільтровувати сегменти з підозрілими характеристиками
- Переваги: Надійність + гнучкість
- Недоліки: Складніше реалізувати

**Ідея 3: Розбиття довгих сегментів**
- Виявляти сегменти з тривалістю >30 секунд
- Розбивати їх на менші частини на основі primary сегментів
- Переваги: Вирішує проблему довгих сегментів
- Недоліки: Може втратити контекст

**Ідея 4: Фільтрація підозрілих сегментів**
- Виявляти сегменти, де `segment.speaker !== originalTrackSpeaker`
- Відфільтровувати такі сегменти або виправляти їх
- Переваги: Вирішує проблему неправильних спікерів
- Недоліки: Може втратити важливий текст

**Ідея 5: Ієрархія довіри**
- Пріоритет 1: `originalTrackSpeaker` (найвища надійність)
- Пріоритет 2: Overlap-based mapping (якщо originalTrackSpeaker недоступний)
- Пріоритет 3: Role-based matching (якщо overlap не знайдено)
- Переваги: Комплексний підхід
- Недоліки: Складність

### 6.2. Вибір найкращого рішення

**Рекомендоване рішення: Комбінований підхід з пріоритетом originalTrackSpeaker**

**Алгоритм**:
1. **Нормалізація спікерів в voice tracks**:
   - Для кожного сегменту: `segment.speaker = originalTrackSpeaker`
   - Це вирішує проблему неправильних спікерів від Speechmatics

2. **Валідація через тривалість**:
   - Відфільтрувати сегменти з тривалістю >30 секунд (підозрілі)
   - Або розбити їх на основі primary сегментів

3. **Валідація через role**:
   - Перевірити, що role спікера співпадає між primary та voice track
   - Якщо не співпадає - використати primary role

4. **Об'єднання з перевірками**:
   - Об'єднувати тільки якщо спікери співпадають (після нормалізації)
   - Об'єднувати тільки якщо тривалість сегменту розумна (<30s)
   - Об'єднувати тільки якщо overlap та similarity в межах норми

---

## ЕТАП 7: ОЦІНКА РІШЕННЯ

### 7.1. Перевірка на вирішення протиріччя

**ТП-1 вирішено?**
- ✅ Так: Використовуємо `originalTrackSpeaker` замість `speaker` з transcription
- ✅ Не втрачаємо точність: Overlap-based mapping залишається як fallback

**ТП-2 вирішено?**
- ✅ Так: Довгі сегменти фільтруються або розбиваються
- ✅ Не втрачаємо текст: Розбиття на основі primary сегментів зберігає текст

**ТП-3 вирішено?**
- ✅ Так: Використовуємо primary для спікерів, voice track для тексту
- ✅ Комбінуємо найкраще з обох джерел

### 7.2. Перевірка на досягнення ІКР

**ІКР досягнуто?**
- ✅ Система сама визначає правильних спікерів (через `originalTrackSpeaker`)
- ✅ Не потребує додаткових ресурсів (використовує наявні дані)
- ✅ Немає шкідливих ефектів (фільтрація та валідація запобігають помилкам)

### 7.3. Оцінка ризиків

**Ризик 1**: Якщо source separation було неправильним, `originalTrackSpeaker` теж буде неправильним
- **Мітигація**: Overlap-based mapping як fallback
- **Валідація**: Role-based перевірка

**Ризик 2**: Фільтрація довгих сегментів може втратити важливий текст
- **Мітигація**: Розбиття замість фільтрації
- **Валідація**: Перевірка через primary сегменти

**Ризик 3**: Складність реалізації
- **Мітигація**: Поетапна реалізація, тестування на кожному етапі

---

## ЕТАП 8: ДЕТАЛІЗАЦІЯ РІШЕННЯ

### 8.1. Конкретний алгоритм

**Крок 1: Нормалізація спікерів в voice tracks**
```javascript
function normalizeVoiceTrackSpeakers(voiceTrackSegments) {
  return voiceTrackSegments.map(seg => ({
    ...seg,
    speaker: seg.originalTrackSpeaker || seg.speaker,  // Використовуємо originalTrackSpeaker
    originalDetectedSpeaker: seg.speaker  // Зберігаємо для діагностики
  }));
}
```

**Крок 2: Фільтрація підозрілих сегментів**
```javascript
function filterSuspiciousSegments(segments, maxDuration = 30.0) {
  return segments.filter(seg => {
    const duration = (seg.end || 0) - (seg.start || 0);
    if (duration > maxDuration) {
      console.warn(`Suspicious long segment: ${duration}s, speaker: ${seg.speaker}`);
      // Можна розбити або відфільтрувати
      return false;  // або розбити на менші частини
    }
    return true;
  });
}
```

**Крок 3: Валідація через role**
```javascript
function validateSpeakerByRole(voiceSeg, primarySeg) {
  if (voiceSeg.role && primarySeg.role) {
    return voiceSeg.role === primarySeg.role;
  }
  return true;  // Якщо role немає, пропускаємо
}
```

**Крок 4: Об'єднання з нормалізованими спікерами**
```javascript
function mergeWithNormalizedSpeakers(primarySegments, normalizedVoiceSegments) {
  // Тепер всі voice track сегменти мають правильний speaker
  // Можна об'єднувати без складного мапінгу
  // Просто перевіряємо: primarySeg.speaker === voiceSeg.speaker
}
```

### 8.2. План впровадження

**Фаза 1: Нормалізація спікерів**
- Модифікувати `collectVoiceTrackSegments` для використання `originalTrackSpeaker`
- Тестувати на реальних даних

**Фаза 2: Фільтрація довгих сегментів**
- Додати перевірку тривалості
- Тестувати на проблемних випадках

**Фаза 3: Валідація через role**
- Додати role-based перевірку
- Тестувати на різних типах діалогів

**Фаза 4: Оптимізація**
- Видалити непотрібний overlap-based mapping (якщо нормалізація працює)
- Спростити код

---

## ЗАВДАННЯ ДЛЯ GPT

**Ти маєш**:

1. **Проаналізувати цей АРИЗ аналіз** та підтвердити чи спростувати кожен етап
2. **Запропонувати додаткові рішення** на основі інших прийомів ТРИЗ
3. **Деталізувати алгоритм** з конкретним кодом
4. **Визначити потенційні проблеми** та способи їх вирішення
5. **Запропонувати метрики** для оцінки якості рішення
6. **Створити план тестування** рішення

**Критерії успіху**:
- Рішення має бути програмним (не LLM-based)
- Має вирішувати всі три основні проблеми
- Має бути простим у реалізації
- Має мати fallback механізми
- Має бути детально протестованим

**Почати з Етапу 1 і пройти через всі етапи АРИЗ, надаючи детальний аналіз та конкретні рекомендації на кожному етапі.**

