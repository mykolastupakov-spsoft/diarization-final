# Demo2: SpeechBrain + Whisper Diarization

Нова демо-сторінка з інтеграцією SpeechBrain для діаризації спікерів та Whisper для транскрипції аудіо.

## Технології

- **SpeechBrain** - для витягування ембедингів голосу та діаризації спікерів
- **Whisper** - для транскрипції аудіо
- **Flask** - Python backend сервер
- **Node.js/Express** - проксі для інтеграції з основним сервером

## Встановлення

### 1. Встановити Python залежності

```bash
pip install -r requirements.txt
```

Це встановить:
- Flask та flask-cors
- SpeechBrain
- OpenAI Whisper
- Librosa для обробки аудіо
- Scikit-learn для кластеризації

### 2. Запуск Flask сервера

```bash
python app_demo2.py
```

Або з вказанням порту:

```bash
DEMO2_PORT=5000 python app_demo2.py
```

Сервер запуститься на порту 5000 (за замовчуванням) або на вказаному порту.

**Примітка:** При першому запуску моделі завантажаться автоматично:
- SpeechBrain ECAPA-TDNN (~100 MB) з HuggingFace
- Whisper base модель (~150 MB)

Це може зайняти 2-5 хвилин.

### 3. Запуск Node.js сервера

```bash
npm start
# або
node server.js
```

Node.js сервер працює на порту 3000 (за замовчуванням) та проксує запити до Flask сервера.

## Використання

1. Відкрийте браузер та перейдіть на:
   ```
   http://localhost:3000/demo2
   ```

2. Завантажте аудіофайл (WAV, MP3, FLAC, M4A) - максимум 100 MB

3. Налаштуйте параметри:
   - **Кількість спікерів** - залиште порожнім для автоматичного визначення
   - **Мова** - виберіть мову або залиште "Авто-визначення"
   - **Довжина сегмента** - довжина сегмента для витягування ембедингів (за замовчуванням 1.5 сек)
   - **Перекриття** - перекриття між сегментами (за замовчуванням 0.5)
   - **Включити транскрипцію** - чи включати транскрипцію Whisper

4. Натисніть **Аналізувати**

5. Перегляньте результати:
   - **Діаризація** - сегменти з визначенням спікерів
   - **Транскрипція** - повний текст та сегменти транскрипції
   - **Об'єднано** - комбінація діаризації та транскрипції

## API Endpoints

### Node.js проксі (рекомендовано)

- `GET /api/demo2/health` - перевірка стану Flask сервера
- `POST /api/demo2/diarize` - діаризація та транскрипція

### Flask сервер (прямий доступ)

- `GET /api/health` - перевірка стану
- `POST /api/diarize` - діаризація та транскрипція

**Параметри запиту (multipart/form-data):**
- `file` - аудіофайл (обов'язково)
- `num_speakers` - кількість спікерів (опціонально)
- `language` - код мови: 'uk', 'en', 'ar', 'ru' (опціонально)
- `segment_duration` - довжина сегмента в секундах (за замовчуванням 1.5)
- `overlap` - перекриття між сегментами 0-1 (за замовчуванням 0.5)
- `include_transcription` - 'true' або 'false' (за замовчуванням 'true')

**Відповідь (JSON):**

```json
{
  "success": true,
  "diarization": {
    "segments": [
      {
        "speaker": 0,
        "start": 0.5,
        "end": 5.2
      }
    ],
    "num_speakers": 2
  },
  "transcription": {
    "full_text": "Повний текст транскрипції...",
    "segments": [
      {
        "start": 0.0,
        "end": 2.5,
        "text": "Текст сегменту"
      }
    ]
  },
  "combined": {
    "segments": [
      {
        "speaker": 0,
        "start": 0.0,
        "end": 2.5,
        "text": "Текст з визначеним спікером"
      }
    ]
  }
}
```

## Налаштування

### Змінні середовища

- `DEMO2_PORT` - порт для Flask сервера (за замовчуванням 5000)
- `DEMO2_FLASK_URL` - URL Flask сервера для Node.js проксі (за замовчуванням http://localhost:5000)

### Параметри діаризації

У файлі `app_demo2.py` можна налаштувати:

- `segment_duration` - довжина сегмента для ембедингів (за замовчуванням 1.5 сек)
- `overlap` - перекриття між сегментами (за замовчуванням 0.5)
- Автоматичне визначення кількості спікерів через евристику

### Модель Whisper

За замовчуванням використовується модель `base`. Для кращої якості можна змінити на `small`, `medium` або `large` у функції `load_models()`:

```python
whisper_model = whisper.load_model("base")  # або "small", "medium", "large"
```

**Примітка:** Більші моделі дають кращу якість, але працюють повільніше та займають більше пам'яті.

## Розв'язання проблем

### Flask сервер не запускається

- Перевірте, чи встановлені всі залежності: `pip install -r requirements.txt`
- Перевірте, чи порт 5000 не зайнятий іншим процесом
- Перевірте логи на наявність помилок

### Моделі не завантажуються

- Перевірте інтернет-з'єднання (моделі завантажуються з HuggingFace)
- Перевірте наявність вільного місця на диску (~250 MB для моделей)
- Спробуйте видалити папку `pretrained_models/` та перезапустити

### Погана якість діаризації

- Збільште `segment_duration` до 2-3 секунд
- Явно вкажіть `num_speakers`, не покладайтеся на автоматику
- Перевірте якість аудіо (чистота звуку, відсутність шуму)

### Помилка "Out of Memory"

- Зменште `segment_duration`
- Зменште `overlap`
- Використовуйте меншу модель Whisper (наприклад, `tiny` замість `base`)
- Розбийте аудіо на менші файли

### Node.js не може підключитися до Flask

- Перевірте, чи Flask сервер запущений
- Перевірте змінну `DEMO2_FLASK_URL` у Node.js
- Перевірте, чи порти не заблоковані файрволом

## Структура файлів

```
diarization-final/
├── app_demo2.py              # Flask сервер
├── public/
│   └── demo2.html           # HTML інтерфейс
├── server.js                 # Node.js сервер з проксі
├── requirements.txt          # Python залежності
└── DEMO2_README.md          # Цей файл
```

## Наступні кроки

- [ ] Додати можливість експорту результатів (JSON, VTT, SRT)
- [ ] Додати візуалізацію діаризації на часовій шкалі
- [ ] Додати можливість розділення треків по спікерах
- [ ] Оптимізувати швидкість обробки для великих файлів
- [ ] Додати підтримку streaming для реал-тайм обробки


