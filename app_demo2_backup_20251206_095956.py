def assess_programmatic_confidence(segments, check_type, matched_criteria_count, total_criteria):
    """
    –û—Ü—ñ–Ω—é—î –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å –ø—Ä–æ–≥—Ä–∞–º–Ω–æ—ó –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –∑–±—ñ–≥—ñ–≤ –∫—Ä–∏—Ç–µ—Ä—ñ—ó–≤.
    
    Args:
        segments: —Å–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç—ñ–≤, —è–∫—ñ –±—É–ª–∏ –æ–±—Ä–æ–±–ª–µ–Ω—ñ
        check_type: —Ç–∏–ø –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ ('continuity', 'mismatch', 'fragmented', 'merge')
        matched_criteria_count: –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫—Ä–∏—Ç–µ—Ä—ñ—ó–≤, —è–∫—ñ –∑–±—ñ–≥–ª–∏—Å—è
        total_criteria: –∑–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫—Ä–∏—Ç–µ—Ä—ñ—ó–≤ –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏
    
    Returns:
        confidence: float 0.0-1.0, –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å —É –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—ñ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏
    """
    if total_criteria == 0:
        return 0.5  # –°–µ—Ä–µ–¥–Ω—è –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å, —è–∫—â–æ –Ω–µ–º–∞—î –∫—Ä–∏—Ç–µ—Ä—ñ—ó–≤
    
    # –ë–∞–∑–æ–≤–∏–π —Ä—ñ–≤–µ–Ω—å –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –≤—ñ–¥—Å–æ—Ç–∫–∞ –∑–±—ñ–≥—ñ–≤
    base_confidence = matched_criteria_count / total_criteria
    
    # –ö–æ—Ä–µ–∫—Ü—ñ—ó –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö —Ç–∏–ø—ñ–≤ –ø–µ—Ä–µ–≤—ñ—Ä–æ–∫
    if check_type == 'continuity':
        # –ü—Ä–∞–≤–∏–ª–æ –Ω–µ–ø–µ—Ä–µ—Ä–≤–Ω–æ—Å—Ç—ñ: –≤–∏—Å–æ–∫–∞ –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å, —è–∫—â–æ –≤—Å—ñ –∫—Ä–∏—Ç–µ—Ä—ñ—ó –∑–±—ñ–≥–ª–∏—Å—è
        if matched_criteria_count == total_criteria:
            return 0.9
        elif matched_criteria_count >= total_criteria * 0.75:
            return 0.7
        else:
            return 0.5
    
    elif check_type == 'mismatch':
        # –í–∏—è–≤–ª–µ–Ω–Ω—è –ø–æ–º–∏–ª–æ–∫: –≤–∏—Å–æ–∫–∞ –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å –¥–ª—è —á—ñ—Ç–∫–∏—Ö –ø–∞—Ç–µ—Ä–Ω—ñ–≤
        if matched_criteria_count == total_criteria:
            return 0.85
        elif matched_criteria_count >= total_criteria * 0.8:
            return 0.65
        else:
            return 0.45
    
    elif check_type == 'fragmented':
        # –†–æ–∑–±–∏—Ç—ñ —Ñ—Ä–∞–∑–∏: –≤–∏—Å–æ–∫–∞ –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å –¥–ª—è –≥—Ä–∞–º–∞—Ç–∏—á–Ω–æ –∑–≤'—è–∑–Ω–∏—Ö —Ñ—Ä–∞–∑
        if matched_criteria_count == total_criteria:
            return 0.9
        elif matched_criteria_count >= total_criteria * 0.8:
            return 0.7
        else:
            return 0.5
    
    elif check_type == 'merge':
        # –û–±'—î–¥–Ω–∞–Ω–Ω—è —Å–µ–≥–º–µ–Ω—Ç—ñ–≤: –≤–∏—Å–æ–∫–∞ –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å –¥–ª—è —Å—É—Å—ñ–¥–Ω—ñ—Ö —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –æ–¥–Ω–æ–≥–æ —Å–ø—ñ–∫–µ—Ä–∞
        if matched_criteria_count == total_criteria:
            return 0.95
        elif matched_criteria_count >= total_criteria * 0.8:
            return 0.75
        else:
            return 0.55
    
    return base_confidence


def apply_programmatic_checks_with_confidence(segments):
    """
    –ó–∞—Å—Ç–æ—Å–æ–≤—É—î –≤—Å—ñ –ø—Ä–æ–≥—Ä–∞–º–Ω—ñ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Ç–∞ –æ—Ü—ñ–Ω—é—î –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å –∫–æ–∂–Ω–æ—ó.
    –ü–æ–≤–µ—Ä—Ç–∞—î —Å–µ–≥–º–µ–Ω—Ç–∏ –∑ –æ—Ü—ñ–Ω–∫–∞–º–∏ –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ —Ç–∞ —Å–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –¥–ª—è –µ—Å–∫–∞–ª–∞—Ü—ñ—ó.
    
    Returns:
        tuple: (fixed_segments, segments_for_escalation, overall_confidence)
        - fixed_segments: –≤–∏–ø—Ä–∞–≤–ª–µ–Ω—ñ —Å–µ–≥–º–µ–Ω—Ç–∏ –∑ –æ—Ü—ñ–Ω–∫–∞–º–∏ –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ
        - segments_for_escalation: —Å–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç—ñ–≤, —è–∫—ñ –ø–æ—Ç—Ä–µ–±—É—é—Ç—å –µ—Å–∫–∞–ª–∞—Ü—ñ—ó –¥–æ LLM
        - overall_confidence: –∑–∞–≥–∞–ª—å–Ω–∞ –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å —É –ø—Ä–æ–≥—Ä–∞–º–Ω–∏—Ö –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞—Ö (0.0-1.0)
    """
    if not segments or len(segments) < 2:
        return segments, [], 1.0
    
    print(f"üîç Applying programmatic checks with confidence assessment...")
    fixed_segments = [seg.copy() for seg in segments]
    segments_for_escalation = []
    confidence_scores = []
    
    # –ö–†–û–ö 1: –ü—Ä–∞–≤–∏–ª–æ –Ω–µ–ø–µ—Ä–µ—Ä–≤–Ω–æ—Å—Ç—ñ —Å–ø—ñ–∫–µ—Ä–∞
    print(f"  üìã Step 1: Speaker continuity rule...")
    before_count = len(fixed_segments)
    fixed_segments = enforce_speaker_continuity_rule(fixed_segments, max_gap=3.0)
    after_count = len(fixed_segments)
    
    # –û—Ü—ñ–Ω—é—î–º–æ –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å: —è–∫—â–æ –æ–±'—î–¥–Ω–∞–ª–∏ —Å–µ–≥–º–µ–Ω—Ç–∏, –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å –∑–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ –∫—Ä–∏—Ç–µ—Ä—ñ—ó–≤
    continuity_confidence = 0.9 if after_count < before_count else 1.0
    for seg in fixed_segments:
        if seg.get('speaker_continuity_fix', False):
            seg['programmatic_confidence'] = continuity_confidence
            if continuity_confidence < 0.7:
                segments_for_escalation.append({
                    'segment': seg,
                    'reason': 'speaker_continuity_low_confidence',
                    'confidence': continuity_confidence
                })
    confidence_scores.append(continuity_confidence)
    
    # –ö–†–û–ö 2: –û–±'—î–¥–Ω–∞–Ω–Ω—è —Å—É—Å—ñ–¥–Ω—ñ—Ö —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –æ–¥–Ω–æ–≥–æ —Å–ø—ñ–∫–µ—Ä–∞
    print(f"  üìã Step 2: Merging consecutive segments...")
    before_count = len(fixed_segments)
    fixed_segments = merge_consecutive_speaker_segments(fixed_segments, max_gap=1.5)
    after_count = len(fixed_segments)
    merge_confidence = 0.95 if after_count < before_count else 1.0
    confidence_scores.append(merge_confidence)
    
    # –ö–†–û–ö 3: –í–∏—è–≤–ª–µ–Ω–Ω—è –ø–æ–º–∏–ª–æ–∫ –ø—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Å–ø—ñ–∫–µ—Ä—ñ–≤ (–∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥—É–º–∫–∞ ‚Üí –ø–∏—Ç–∞–Ω–Ω—è)
    print(f"  üìã Step 3: Speaker mismatch detection...")
    fixed_segments = detect_and_fix_speaker_mismatch_after_complete_statement(fixed_segments)
    mismatch_confidence = 0.85
    for seg in fixed_segments:
        if seg.get('needs_role_verification', False):
            seg['programmatic_confidence'] = mismatch_confidence
            segments_for_escalation.append({
                'segment': seg,
                'reason': 'speaker_mismatch_needs_verification',
                'confidence': mismatch_confidence
            })
    confidence_scores.append(mismatch_confidence)
    
    # –ö–†–û–ö 4: –í–∏—è–≤–ª–µ–Ω–Ω—è —Ä–æ–∑–±–∏—Ç–∏—Ö —Ñ—Ä–∞–∑
    print(f"  üìã Step 4: Fragmented phrase detection...")
    before_count = len(fixed_segments)
    fixed_segments = detect_and_merge_fragmented_phrases(fixed_segments)
    after_count = len(fixed_segments)
    fragmented_confidence = 0.9 if after_count < before_count else 1.0
    for seg in fixed_segments:
        if seg.get('fragmented_merge', False):
            seg['programmatic_confidence'] = fragmented_confidence
            if fragmented_confidence < 0.7:
                segments_for_escalation.append({
                    'segment': seg,
                    'reason': 'fragmented_phrase_low_confidence',
                    'confidence': fragmented_confidence
                })
    confidence_scores.append(fragmented_confidence)
    
    # –û–±—á–∏—Å–ª—é—î–º–æ –∑–∞–≥–∞–ª—å–Ω—É –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å
    overall_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 1.0
    
    print(f"‚úÖ Programmatic checks completed:")
    print(f"   - Overall confidence: {overall_confidence:.2f}")
    print(f"   - Segments for escalation: {len(segments_for_escalation)}")
    
    return fixed_segments, segments_for_escalation, overall_confidence
